{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quarantine_covid19_behavior_analysis",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kofYesiQd6fnKQlHtO1hARhAwbaZS5eB",
      "authorship_tag": "ABX9TyPhuEH1RNtfp8o+nz3SP4f7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelobenedito/quarantine_covid19_behavior_analysis/blob/master/quarantine_covid19_behavior_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoKhvChd0eNA",
        "colab_type": "text"
      },
      "source": [
        "#**Quarantine Covid-19 Behavior Analysis**\n",
        "\n",
        "*It will be collect data tweets about COVID-19, quarantine and related about. This content will analysed to extract sentiment and main user behavior that makes don't stay home.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcgjMRwh6yfe",
        "colab_type": "text"
      },
      "source": [
        "## **1 - Extract and preprocessing data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uqUJtTtHyV",
        "colab_type": "text"
      },
      "source": [
        "**Install libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md6SYud4tH9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "eb9df9b3-2613-4c4b-cb85-9613cfeebb51"
      },
      "source": [
        "!pip3 install unidecode\n",
        "!pip3 install twitterscraper\n",
        "!pip3 install emoji"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: twitterscraper in /usr/local/lib/python3.6/dist-packages (1.6.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (2.23.0)\n",
            "Requirement already satisfied: coala-utils~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (0.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (4.2.6)\n",
            "Requirement already satisfied: billiard in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (3.6.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->twitterscraper) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (1.24.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWSeZqYvFjl3",
        "colab_type": "text"
      },
      "source": [
        "**Required imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frum5NdVVPzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7f368494-af25-4a38-cdb6-7d282213ab88"
      },
      "source": [
        "import string\n",
        "import time\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from unidecode import unidecode\n",
        "from twitterscraper import query_tweets\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from emoji import demojize\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy0c6-DS9gYh",
        "colab_type": "text"
      },
      "source": [
        "**Create a funcion to search tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0rre9-9hNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_tweets(search_filter, since, until, limit, language):\n",
        "  return query_tweets(query = search_filter, begindate = since, enddate = until, limit = limit, lang = language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ92bhg6VDuz",
        "colab_type": "text"
      },
      "source": [
        "**Data preprocessing**\n",
        "\n",
        "This process is used to preprocess the tweet text:\n",
        "\n",
        " - Tokenize words;\n",
        " - Remove all stop words; \n",
        " - Punctuaction rules; \n",
        " - Unused characters;\n",
        " - Links from tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z3s-jZIVEGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(df):\n",
        "  # Converting to lowercase\n",
        "  tweets = df.text.str.lower()\n",
        "\n",
        "  # Removing punctuation rules\n",
        "  tweets = tweets.str.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  # Removing unused links\n",
        "  tweets = tweets.str.replace(r\"(http|@)\\S+\", \"\")\n",
        "\n",
        "  # Remove special chars\n",
        "  tweets = tweets.apply(demojize)\n",
        "  tweets = tweets.str.replace(r\"::\", \": :\")\n",
        "  tweets = tweets.str.replace(r\"’\", \"'\")\n",
        "  tweets = tweets.str.replace(r\"[^a-z\\':_]\", \" \")\n",
        "\n",
        "  # Remove repetitions\n",
        "  pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
        "  tweets = tweets.str.replace(pattern, r\"\\1\")\n",
        "\n",
        "  # Transform short negation form\n",
        "  tweets = tweets.str.replace(r\"(nao| n | ñ )\", 'não')\n",
        "\n",
        "  # Spliting text into words\n",
        "  # tweets = word_tokenize(tweets, 'english')\n",
        "\n",
        "  # Removing stop words\n",
        "  sw = stopwords.words('portuguese')\n",
        "  sw.remove('não')\n",
        "\n",
        "  tweets = tweets.apply(\n",
        "      lambda tweet: ' '.join([word for word in tweet.split() if word not in sw])\n",
        "  )\n",
        "\n",
        "  return tweets"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rw7hTfcGwi9",
        "colab_type": "text"
      },
      "source": [
        "**Defining filters used in search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odq6flq8HK4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" não estou saindo \"não estou saindo\" (quarentena OR covid) (#covid-19 OR #coronavírus OR #coronavirus OR #covid OR #quarentena) lang:pt until:2020-01-31 since:2020-01-01 -filter:replies \"\"\"\n",
        "\n",
        "contains_both_words = ''\n",
        "exact_phrase = ''\n",
        "contains_any_words = '(quarentena OR covid OR coronavirus OR isolamento OR festa OR role OR evento OR balada OR sair OR saindo)'\n",
        "contains_any_hashtags = ''\n",
        "no_retweet = '-filter:replies'\n",
        "language = 'pt'\n",
        "since = dt.date(2020,1,1)\n",
        "until = dt.date(2020,1,2)\n",
        "limit = 10\n",
        "\n",
        "search_filter = contains_both_words + ' ' + exact_phrase + ' ' + contains_any_words + ' ' + contains_any_hashtags + ' ' + no_retweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqNMr2yxIl6j",
        "colab_type": "text"
      },
      "source": [
        "**Extracting tweets based on search filter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEIS2-32Ip_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = search_tweets(search_filter, since, until, limit, language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxeEFuANdoZQ",
        "colab_type": "text"
      },
      "source": [
        "**Transform Json to DataFrame and export to CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B1HDPGido0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'tweet_id': tweet.tweet_id, \n",
        "    'text': unidecode(tweet.text),  \n",
        "    'tweet_url': tweet.tweet_url,\n",
        "    'retweets': tweet.retweets,\n",
        "    'replies': tweet.replies,\n",
        "    'is_replied': tweet.is_replied,\n",
        "    'is_reply_to': tweet.is_reply_to,\n",
        "    'user_id': tweet.user_id, \n",
        "    'screenname': tweet.screenname,\n",
        "    'created_at': tweet.timestamp\n",
        "} for tweet in tweets)\n",
        "\n",
        "df.to_csv('tweets.csv', encoding = 'utf-8', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf-B19NsJLJP",
        "colab_type": "text"
      },
      "source": [
        "**Printing found tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dI6Q2SbYbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3ae7d03-c421-4a55-b69b-1d3b1248563d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>retweets</th>\n",
              "      <th>replies</th>\n",
              "      <th>is_replied</th>\n",
              "      <th>is_reply_to</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1212523890540462082</td>\n",
              "      <td>Esse eu vou da tchau pra vida de festa, ta bom?</td>\n",
              "      <td>/NetoMiguel02/status/1212523890540462082</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1190617786294374400</td>\n",
              "      <td>2020-01-01 23:59:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1212523890439786496</td>\n",
              "      <td>o quanto as coisas demoram p sair da minha cab...</td>\n",
              "      <td>/amandiiiix/status/1212523890439786496</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1064533534109589504</td>\n",
              "      <td>2020-01-01 23:59:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1212523879970885633</td>\n",
              "      <td>meu momento pos role sempre e baseado em pensa...</td>\n",
              "      <td>/inouesz/status/1212523879970885633</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1046604175717601280</td>\n",
              "      <td>2020-01-01 23:59:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1212523878477635584</td>\n",
              "      <td>Deu janeiro e eu quero sair do emprego eai kkk...</td>\n",
              "      <td>/Haile_Din/status/1212523878477635584</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1032060705221083137</td>\n",
              "      <td>2020-01-01 23:59:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1212523878230171648</td>\n",
              "      <td>o que vc diria?\\n\\n1- cuida dela pq ela e espe...</td>\n",
              "      <td>/Laura_Liiotta/status/1212523878230171648</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>723473031293743104</td>\n",
              "      <td>2020-01-01 23:59:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...          created_at\n",
              "0  1212523890540462082  ... 2020-01-01 23:59:57\n",
              "1  1212523890439786496  ... 2020-01-01 23:59:57\n",
              "2  1212523879970885633  ... 2020-01-01 23:59:55\n",
              "3  1212523878477635584  ... 2020-01-01 23:59:54\n",
              "4  1212523878230171648  ... 2020-01-01 23:59:54\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKPqylLAZ3PV",
        "colab_type": "text"
      },
      "source": [
        "**Open stored tweets from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78qAC2KDZ2fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b9113999-c378-4770-8164-6e7d089e2992"
      },
      "source": [
        "df = pd.read_csv('tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>retweets</th>\n",
              "      <th>replies</th>\n",
              "      <th>is_replied</th>\n",
              "      <th>is_reply_to</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.210000e+18</td>\n",
              "      <td>Esse eu vou da tchau pra vida de festa, ta bom?</td>\n",
              "      <td>/NetoMiguel02/status/1212523890540462082</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.190000e+18</td>\n",
              "      <td>1/1/2020 23:59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.210000e+18</td>\n",
              "      <td>o quanto as coisas demoram p sair da minha cab...</td>\n",
              "      <td>/amandiiiix/status/1212523890439786496</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.060000e+18</td>\n",
              "      <td>1/1/2020 23:59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.210000e+18</td>\n",
              "      <td>meu momento pos role sempre e baseado em pensa...</td>\n",
              "      <td>/inouesz/status/1212523879970885633</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.050000e+18</td>\n",
              "      <td>1/1/2020 23:59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.210000e+18</td>\n",
              "      <td>Deu janeiro e eu quero sair do emprego eai kkk...</td>\n",
              "      <td>/Haile_Din/status/1212523878477635584</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.030000e+18</td>\n",
              "      <td>1/1/2020 23:59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.210000e+18</td>\n",
              "      <td>o que vc diria?\\n\\n1- cuida dela pq ela e espe...</td>\n",
              "      <td>/Laura_Liiotta/status/1212523878230171648</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>7.230000e+17</td>\n",
              "      <td>1/1/2020 23:59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tweet_id  ... class\n",
              "0  1.210000e+18  ...     0\n",
              "1  1.210000e+18  ...     0\n",
              "2  1.210000e+18  ...     0\n",
              "3  1.210000e+18  ...     0\n",
              "4  1.210000e+18  ...     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCTyUI_0PdBe",
        "colab_type": "text"
      },
      "source": [
        "**Preproccessing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4kboFYWPdO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = preprocess_data(df)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TFhL89A6f0F",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessed tweets containing a classification for each one**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XikS4p3O6fEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6d789318-eafc-4639-fd70-81194592a671"
      },
      "source": [
        "preprocessed_data = pd.DataFrame({'tweets': tweets, 'class': df['class']})\n",
        "preprocessed_data.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vou tchau pra vida festa ta bom</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>quanto coisas demoram p sair cabeca eh inacred...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>momento pos role sempre baseado pensar histori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>deu janeiro quero sair emprego eai k</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vc diria cuida pq especial pau cu pede dsclp v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  class\n",
              "0                    vou tchau pra vida festa ta bom      0\n",
              "1  quanto coisas demoram p sair cabeca eh inacred...      0\n",
              "2  momento pos role sempre baseado pensar histori...      0\n",
              "3               deu janeiro quero sair emprego eai k      0\n",
              "4  vc diria cuida pq especial pau cu pede dsclp v...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChh4lPc7TX3",
        "colab_type": "text"
      },
      "source": [
        "## **2 - Training process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-7iWMMoQiFP"
      },
      "source": [
        "**Install libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcIuD-tdQZxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS7SNnWwsdyM",
        "colab_type": "text"
      },
      "source": [
        "**Transform text to vector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SjdXf7EseHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit(preprocessed_data['tweets'])\n",
        "\n",
        "vectorized_tweets = cv.transform(preprocessed_data['tweets'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "brpX4tQjRMw_"
      },
      "source": [
        "**Split x and y (feature and target)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5l-vzJolHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vectorized_tweets,\n",
        "                                                    preprocessed_data['class'],\n",
        "                                                    test_size=0.2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZyX4LkUogVS",
        "colab_type": "text"
      },
      "source": [
        "### **2.0.1 - MLPClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSeKiC1BSu6D",
        "colab_type": "text"
      },
      "source": [
        "**Create a Multilayer Perceptron Model**\n",
        "\n",
        "- Hidden layers = 1\n",
        "- Neurons = 10\n",
        "- Learning rate = 0.01\n",
        "- Max iteration = 500\n",
        "- Optimizer = Stochastic Gradient Descent with no batch-size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTEyzENHSrZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"mlp_model = MLPClassifier(hidden_layer_sizes=(10), \n",
        "                          solver='sgd', \n",
        "                          learning_rate_init=0.01,\n",
        "                          max_iter=500,\n",
        "                          random_state=113)\"\"\"\n",
        "\n",
        "mlp_model = MLPClassifier(learning_rate_init=0.01,\n",
        "                          random_state=42)                "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z0ij7oaUpFb",
        "colab_type": "text"
      },
      "source": [
        "**Train the MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZFGxkanU0fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c8270f77-c380-46b8-de29-0a91662f12d4"
      },
      "source": [
        "mlp_model.fit(X_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.01, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=42, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDXzDABYnCHj",
        "colab_type": "text"
      },
      "source": [
        "**Score from MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5jcNKzGnCdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2002d1e4-ecb3-4e63-c859-e3db7905b1a5"
      },
      "source": [
        "score = mlp_model.score(X_test, y_test)\n",
        "score = round((score * 100.0), 2)\n",
        "print('{} [INFO] The MLP model has {}% of accuracy'.format(dt.datetime.now(), score))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 23:51:20.999001 [INFO] The MLP model has 75.0% of accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07slT345Wy1w",
        "colab_type": "text"
      },
      "source": [
        "**Predict tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxnj_CknoWgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "724c3691-7377-43ec-ebbf-e783d1541a6c"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15    0\n",
            "13    0\n",
            "0     0\n",
            "5     0\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPGvW6DgW4y5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d7c4dd5e-e26f-483e-e447-6bbde9c1becf"
      },
      "source": [
        "\"\"\"data = pd.DataFrame({'english_text': ['going market now', \n",
        "                     'tomorrow cool party', \n",
        "                     'want leave home'], 'class': [0, 1, 0]})\n",
        "\n",
        "new_tweets = preprocess_data(data)\n",
        "data = pd.DataFrame({'tweets': new_tweets, 'class': data['class']})\n",
        "\n",
        "tweet_count =  cv.transform(data['tweets'])\n",
        "tweet_pred = mlp_model.predict(tweet_count)\n",
        "print(tweet_pred)\n",
        "\n",
        "score = accuracy_score(tweet_pred, data['class'])\n",
        "score = round((score * 100.0), 2)\n",
        "print('{} [INFO] The MLP model has {}% of accuracy'.format(dt.datetime.now(), score))\"\"\"\n",
        "\n",
        "tweet_pred = mlp_model.predict(X_test)\n",
        "print(\"Predicted: \", tweet_pred)\n",
        "print(y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  [0 1 0 0]\n",
            "15    0\n",
            "13    0\n",
            "0     0\n",
            "5     0\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyyxjlWnWtpm",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoadc_T0W5tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xKG3J_jC8LFI"
      },
      "source": [
        "### **2.0.2 - Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pAJl5Pqi8LFJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6zqRz0M58Rxv"
      },
      "source": [
        "### **2.0.3 - Sequential Minimal Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d6I6HZT58Rxw",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}