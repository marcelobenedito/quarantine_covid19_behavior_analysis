{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quarantine_covid19_behavior_analysis",
      "provenance": [],
      "collapsed_sections": [
        "Gu4fYre7iTxl",
        "xcgjMRwh6yfe",
        "FQ92bhg6VDuz"
      ],
      "toc_visible": true,
      "mount_file_id": "1kofYesiQd6fnKQlHtO1hARhAwbaZS5eB",
      "authorship_tag": "ABX9TyOu+fn3BsEc/JzR9ZsN8NJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelobenedito/quarantine_covid19_behavior_analysis/blob/master/quarantine_covid19_behavior_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoKhvChd0eNA"
      },
      "source": [
        "#**Quarantine Covid-19 behavior analysis**\n",
        "\n",
        "*It will be collect data tweets about COVID-19, quarantine and related about. This content will analysed to extract sentiment and main user behavior that makes don't stay home.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu4fYre7iTxl"
      },
      "source": [
        "## **1. Initial settings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uqUJtTtHyV"
      },
      "source": [
        "**Install libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md6SYud4tH9y",
        "outputId": "2590d892-8070-40fc-9f88-c7693d734a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip3 install unidecode\n",
        "!pip3 install emoji\n",
        "!pip3 install joblib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=6f2b679a93220c600e7f2a3e42b254dbf644cdb1daebf2920a7ea54ce93f3969\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWSeZqYvFjl3"
      },
      "source": [
        "**Required imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frum5NdVVPzd"
      },
      "source": [
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import tweepy\n",
        "import time\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from unidecode import unidecode\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from emoji import demojize\n",
        "from pytz import timezone"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9fkGHWyiP1U"
      },
      "source": [
        "**Mounting drive and downloading stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4f1VoFLiEx6",
        "outputId": "a78bbae7-a9bd-42d4-9edd-5b1a597d7e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPa7JRcxuJSL"
      },
      "source": [
        "**Add America/São Paulo timezone for this notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDqGRJKSuJsL",
        "outputId": "d538b192-4cae-46b7-f1b8-2c0a8de04703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/America/Sao_Paulo /etc/localtime\n",
        "!date\n",
        "\n",
        "tz = timezone('America/Sao_Paulo')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Oct  4 10:18:19 -03 2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdYRMNSY6eXm",
        "outputId": "a89aa67c-2255-4c5d-9082-adf5fc255f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/TCC/credentials'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TCC/credentials\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyuLOEc26mIM"
      },
      "source": [
        "from credentials import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcgjMRwh6yfe"
      },
      "source": [
        "## **2. Extract tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4D826YpwR0H"
      },
      "source": [
        "cd '../Tweets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiaZJKWawjuD"
      },
      "source": [
        "**Handling the rate limit using cursors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51J1dHPZwZcO"
      },
      "source": [
        "def limit_handled(cursor, finishes):\n",
        "    while True:\n",
        "        try:\n",
        "            if finishes == True:\n",
        "              return\n",
        "            yield cursor.next()\n",
        "        except (tweepy.RateLimitError, StopIteration):\n",
        "            if finishes == True:\n",
        "              return\n",
        "            else:\n",
        "              print('\\r{} [tweepy.RateLimitError] Rate limit exception...'.format(dt.datetime.now().astimezone(tz)), end='')\n",
        "              time.sleep(15*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy0c6-DS9gYh"
      },
      "source": [
        "**Create a funcion to search tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0rre9-9hNa"
      },
      "source": [
        "def search_tweets(search_filter, since, until, limit, language):\n",
        "  finishes = False\n",
        "  for tweet in tweepy.Cursor(api.search, q=search_filter, until=until, lang=language, tweet_mode=\"extended\").items(limit):\n",
        "    tweets.append(tweet)\n",
        "    print('\\r{} [INFO] {} collected tweets!'.format(dt.datetime.now().astimezone(tz), len(tweets)), end='');\n",
        "    if limit != None and len(tweets) == limit:\n",
        "      return tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQNOvOcA4Odw"
      },
      "source": [
        "**API authentication**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlQCTLh_4OHV"
      },
      "source": [
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rw7hTfcGwi9"
      },
      "source": [
        "**Defining filters used in search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odq6flq8HK4-"
      },
      "source": [
        "\"\"\" não estou saindo \"não estou saindo\" (quarentena OR covid) (#covid-19 OR #coronavírus OR #coronavirus OR #covid OR #quarentena) lang:pt until:2020-01-31 since:2020-01-01 -filter:replies \"\"\"\n",
        "\n",
        "contains_both_words = ''\n",
        "exact_phrase = ''\n",
        "#contains_any_words = '(quarentena OR covid OR coronavirus OR isolamento OR festa OR role OR evento OR balada OR sair OR saindo)'\n",
        "contains_any_words = ('(quarentena OR covid OR covid-19 OR coronavirus OR coronavírus'\n",
        "                      ' OR isolamento OR isolado OR isolar OR festa OR rolê OR role'\n",
        "                      ' OR evento OR balada OR sair OR saindo OR indo OR vamos OR vou'\n",
        "                      ' OR churrasco OR churras OR churrascão OR rodeio OR show'\n",
        "                      ' OR viagem OR viajar)')\n",
        "contains_any_hashtags = ''\n",
        "no_retweet = ''\n",
        "language = 'pt'\n",
        "#since = dt.date(2020,1,1)\n",
        "until = dt.date.today() - dt.timedelta(days=7)\n",
        "since = 'since:2020-01-01'\n",
        "#until = 'until:2020-07-01'\n",
        "limit = 30000\n",
        "\n",
        "search_filter = contains_both_words + ' ' + exact_phrase + ' ' + contains_any_words + ' ' + contains_any_hashtags + ' ' + since + no_retweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqNMr2yxIl6j"
      },
      "source": [
        "**Extracting tweets based on search filter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEIS2-32Ip_j",
        "outputId": "2ebd67e3-3d19-4d97-c7c8-82847d80e53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tweets = []\n",
        "started_at = dt.datetime.now()\n",
        "print('{} [INFO] starting search...'.format(dt.datetime.now().astimezone(tz)))\n",
        "tweets = search_tweets(search_filter, since, until, limit, language)\n",
        "finished_at = dt.datetime.now()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 10:03:00.511076-03:00 [INFO] starting search...\n",
            "2020-10-03 12:49:05.846528-03:00 [INFO] 30000 collected tweets!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxeEFuANdoZQ"
      },
      "source": [
        "**Transform Json to DataFrame and export to CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B1HDPGido0k"
      },
      "source": [
        "df = pd.DataFrame({\n",
        "      'created_at': tweet.created_at,\n",
        "      'user_id': tweet.user.id, \n",
        "      'screen_name': tweet.user.screen_name,\n",
        "      'geo': tweet.geo,\n",
        "      'coordinates': tweet.coordinates,\n",
        "      'place': tweet.place,\n",
        "      'tweet_id': tweet.id, \n",
        "      'text': unidecode(tweet.full_text),\n",
        "      'class': ''\n",
        "  } for tweet in tweets)\n",
        "\n",
        "df.to_csv('tweets_{}.csv'.format(dt.datetime.now().astimezone(tz)), encoding = 'utf-8', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf-B19NsJLJP"
      },
      "source": [
        "**Printing found tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dI6Q2SbYbP",
        "outputId": "a495eb45-ea10-4324-90b6-4ce85b910bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-09-25 23:59:59</td>\n",
              "      <td>1207713857310986242</td>\n",
              "      <td>taeminfoxy</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1309643847857827841</td>\n",
              "      <td>@euphoriajeonjkk vou fazer da jisoo, mas ele v...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-09-25 23:59:59</td>\n",
              "      <td>1201458114161238016</td>\n",
              "      <td>patty_harleyy</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1309643847731998720</td>\n",
              "      <td>@3LsApaixonada Vou pedir a ela amg</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-09-25 23:59:59</td>\n",
              "      <td>1184455667794493441</td>\n",
              "      <td>dutrinhamari</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1309643847425814531</td>\n",
              "      <td>RT @luisasonza: e vou usar amanha dnv KKKKK gn...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-09-25 23:59:59</td>\n",
              "      <td>3394646543</td>\n",
              "      <td>zayoungie</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1309643847404793858</td>\n",
              "      <td>perai que eu vou procurar e ficar triste \\n#Ja...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-09-25 23:59:59</td>\n",
              "      <td>759844528895340544</td>\n",
              "      <td>VictoriaHGonz</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1309643847392276480</td>\n",
              "      <td>abrindo minha cerveja, pois vou estudar classi...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           created_at  ...  class\n",
              "0 2020-09-25 23:59:59  ...       \n",
              "1 2020-09-25 23:59:59  ...       \n",
              "2 2020-09-25 23:59:59  ...       \n",
              "3 2020-09-25 23:59:59  ...       \n",
              "4 2020-09-25 23:59:59  ...       \n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97A9FfFQMoCl"
      },
      "source": [
        "**Write to json file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFbmo1Zo8reZ",
        "outputId": "740cb4c9-297d-4309-abd0-bad39ab82de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame(tweets)\n",
        "df.to_json('tweets_{}.json'.format(dt.datetime.now().astimezone(tz)))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Status(_api=&lt;tweepy.api.API object at 0x7f3820...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Status(_api=&lt;tweepy.api.API object at 0x7f3820...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Status(_api=&lt;tweepy.api.API object at 0x7f3820...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Status(_api=&lt;tweepy.api.API object at 0x7f3820...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Status(_api=&lt;tweepy.api.API object at 0x7f3820...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  Status(_api=<tweepy.api.API object at 0x7f3820...\n",
              "1  Status(_api=<tweepy.api.API object at 0x7f3820...\n",
              "2  Status(_api=<tweepy.api.API object at 0x7f3820...\n",
              "3  Status(_api=<tweepy.api.API object at 0x7f3820...\n",
              "4  Status(_api=<tweepy.api.API object at 0x7f3820..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ92bhg6VDuz"
      },
      "source": [
        "## **3. Preprocessing**\n",
        "\n",
        "This process is used to preprocess the tweet text:\n",
        "\n",
        " - Tokenize words;\n",
        " - Remove all stop words; \n",
        " - Punctuaction rules; \n",
        " - Unused characters;\n",
        " - Links from tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huGLWK4oxhgc",
        "outputId": "01b9e90c-b944-4cbd-d43c-7768146e6418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "cd '../Tweets'"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TCC/Tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z3s-jZIVEGS"
      },
      "source": [
        "def preprocessing(pd_serie):\n",
        "\n",
        "  # Converting to lowercase\n",
        "  pd_serie = pd_serie.str.lower()\n",
        "\n",
        "  # Removing punctuation rules\n",
        "  pd_serie = pd_serie.str.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  # Removing unused links\n",
        "  pd_serie = pd_serie.str.replace(r\"(http|@)\\S+\", \"\")\n",
        "\n",
        "  # Transform short negation form\n",
        "  pd_serie = pd_serie.str.replace(r\"(nao| n | ñ )\", 'não')\n",
        "\n",
        "  # Remove special chars\n",
        "  pd_serie = pd_serie.apply(demojize)\n",
        "  pd_serie = pd_serie.str.replace(r\"::\", \": :\")\n",
        "  pd_serie = pd_serie.str.replace(r\"’\", \"'\")\n",
        "  pd_serie = pd_serie.str.replace(r\"[^a-z\\':_]\", \" \")\n",
        "\n",
        "  # Remove repetitions\n",
        "  pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
        "  pd_serie = pd_serie.str.replace(pattern, r\"\\1\")\n",
        "\n",
        "  # Removing stop words\n",
        "  sw = stopwords.words('portuguese')\n",
        "  sw.remove('não')\n",
        "\n",
        "  pd_serie = pd_serie.apply(\n",
        "      lambda pd_serie: ' '.join([word for word in pd_serie.split() if word not in sw])\n",
        "  )\n",
        "\n",
        "  return pd_serie"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyQl1I03hPE9"
      },
      "source": [
        "**Add negation tag to make emphasis in a negative phrase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw5uKVIfhPu5"
      },
      "source": [
        "def negative_phrase(phrase):\n",
        "  negative_word = 'não'\n",
        "  has_nagative_word = False\n",
        "  new_phrase = []\n",
        "  for word in phrase.split():\n",
        "    if has_negative_word == True:\n",
        "      word = word + '_NÃO'\n",
        "    if word == negative_word:\n",
        "      has_negative_word = True\n",
        "    new_phrase.append(word)\n",
        "  return (' '.join(new_phrase))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKPqylLAZ3PV"
      },
      "source": [
        "**Open stored tweets from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78qAC2KDZ2fe",
        "outputId": "c28e7d6a-acc5-4313-f463-1bc30b8d9749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8/12/2020 23:59</td>\n",
              "      <td>1.240000e+18</td>\n",
              "      <td>lavnia57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>Ia dar um chutao nela p sair da frente kkkkkkk...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8/12/2020 23:59</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>mendsbridgerton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>Eu sempre te achei famosinha ai eu tinha medo ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8/12/2020 23:59</td>\n",
              "      <td>1.060000e+18</td>\n",
              "      <td>jhe_yaya</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>RT @clatruvs: eu no banheiro da balada falando...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8/12/2020 23:59</td>\n",
              "      <td>1.270000e+18</td>\n",
              "      <td>Yasminpaivax</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>RT @clatruvs: eu no banheiro da balada falando...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8/12/2020 23:59</td>\n",
              "      <td>1.280000e+18</td>\n",
              "      <td>kopp_taliaa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.290000e+18</td>\n",
              "      <td>Mano pq sair falando?? pqp</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        created_at  ...  class\n",
              "0  8/12/2020 23:59  ...      0\n",
              "1  8/12/2020 23:59  ...      0\n",
              "2  8/12/2020 23:59  ...      0\n",
              "3  8/12/2020 23:59  ...      0\n",
              "4  8/12/2020 23:59  ...      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhKsfzWINh8s"
      },
      "source": [
        "**Count lines in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-4NlBLnNhZm",
        "outputId": "a2284e60-0307-490d-e302-9b559f3460cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df.text.count()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnSbm_92O5Oc"
      },
      "source": [
        "**Removing duplicate lines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_sDSborO4yK"
      },
      "source": [
        "df.drop_duplicates(['text'], inplace=True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePRTWXKTSYlm"
      },
      "source": [
        "**Count lines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP0PhsEWSVjT",
        "outputId": "3aef5986-51c9-4dcb-c650-eb2cc7fdc810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df.text.count()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCTyUI_0PdBe"
      },
      "source": [
        "**Preproccessing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4kboFYWPdO9",
        "outputId": "66e0ba01-ed85-4a98-a044-e1f7844ecf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "classes = df['class']\n",
        "tweets = df.text\n",
        "tweets = preprocessing(tweets)\n",
        "tweets"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       ia dar chutao nela p sair frente k\n",
              "1        sempre achei famosinha ai medo interagir vamos...\n",
              "2        rt clatruvs banheiro balada falando pra menina...\n",
              "4                                 mano pq sair falando pqp\n",
              "5        doudementana entao vamos ficar separadas pq eu...\n",
              "                               ...                        \n",
              "33721    rt iasgomes favor doria fiel protocolo n tome ...\n",
              "33722    mlkd ta td aq base vou clc beat p noix resenha...\n",
              "33723    mafecustodio real to entendendo so to indo ta ...\n",
              "33724    vou voltar malhar segunda aff vou ficar chata ...\n",
              "33725    queria ta churrasco familia cantando molejo ma...\n",
              "Name: text, Length: 24948, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChh4lPc7TX3"
      },
      "source": [
        "## **4. Training and predict process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-7iWMMoQiFP"
      },
      "source": [
        "**Required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcIuD-tdQZxC"
      },
      "source": [
        "import sklearn\n",
        "import joblib\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZyX4LkUogVS"
      },
      "source": [
        "### **3.1 - MLPClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSeKiC1BSu6D"
      },
      "source": [
        "**Create a Multilayer Perceptron Model**\n",
        "\n",
        "- Hidden layers = 1\n",
        "- Neurons = 10\n",
        "- Learning rate = 0.01\n",
        "- Max iteration = 500\n",
        "- Optimizer = Stochastic Gradient Descent with no batch-size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTEyzENHSrZ1"
      },
      "source": [
        "\"\"\"mlp_model = MLPClassifier(hidden_layer_sizes=(10), \n",
        "                          solver='sgd', \n",
        "                          learning_rate_init=0.01,\n",
        "                          max_iter=500,\n",
        "                          random_state=113)\"\"\"\n",
        "\n",
        "mlp_model = MLPClassifier(learning_rate_init=0.01,\n",
        "                          random_state=42)                "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTWAD5QhVa19"
      },
      "source": [
        "**Create pipeline for MLP classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZI0X9eWbTR"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('model', mlp_model)])\n",
        "\n",
        "pipe_bigrams = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))), ('model', mlp_model)])\n",
        "\n",
        "pipe_negation = Pipeline([\n",
        "  ('vectorizer', CountVectorizer(tokenizer=lambda phrase: negative_phrase(phrase))), \n",
        "  ('model', mlp_model)\n",
        "])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brpX4tQjRMw_"
      },
      "source": [
        "**Split x and y (feature and target)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5l-vzJolHu"
      },
      "source": [
        "train_size=0.8\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets,\n",
        "                                                    classes,\n",
        "                                                    train_size=train_size)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXRGNZQinqrW",
        "outputId": "151d4b8e-6568-4978-dea2-c152b9c5e9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "pd.DataFrame({'tweet': X_train, 'class': y_train})"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>vou estrear filme mulher feia mundo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20253</th>\n",
              "      <td>vc quiser gente acorda antes sol nascer vc mul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17331</th>\n",
              "      <td>vamos fazer outro galo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5788</th>\n",
              "      <td>carloscezarcjr stfvergonhamundial ira exigir d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22412</th>\n",
              "      <td>homem quer acabar time qualquer maneira arrasc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14093</th>\n",
              "      <td>rt paparazzorn domenec torrent desembarcando r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>ment sbtw neymarjr serio voce ja pra balada ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17019</th>\n",
              "      <td>ah n vou descer xingo nela agora</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17420</th>\n",
              "      <td>referencia marcelinho lendo contos eroticos ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13892</th>\n",
              "      <td>perdi jogo pq tava trampando vou demitir</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19958 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  class\n",
              "565                  vou estrear filme mulher feia mundo      0\n",
              "20253  vc quiser gente acorda antes sol nascer vc mul...      0\n",
              "17331                             vamos fazer outro galo      0\n",
              "5788   carloscezarcjr stfvergonhamundial ira exigir d...      0\n",
              "22412  homem quer acabar time qualquer maneira arrasc...      0\n",
              "...                                                  ...    ...\n",
              "14093  rt paparazzorn domenec torrent desembarcando r...      0\n",
              "13535  ment sbtw neymarjr serio voce ja pra balada ne...      0\n",
              "17019                   ah n vou descer xingo nela agora      0\n",
              "17420  referencia marcelinho lendo contos eroticos ag...      0\n",
              "13892           perdi jogo pq tava trampando vou demitir      0\n",
              "\n",
              "[19958 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGOCl6-ntcI",
        "outputId": "c61ae01d-95a3-48e6-b68c-4205a5a3c98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "pd.DataFrame({'tweet': X_test, 'class': y_test})"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6155</th>\n",
              "      <td>gente antiga starlanterns segue nessa conra ai...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13614</th>\n",
              "      <td>rafinha realmente sair fudeu vezkk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7381</th>\n",
              "      <td>n vou fala nada pq gremio k joga contra ceara ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23925</th>\n",
              "      <td>vamos flamengo crlh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24251</th>\n",
              "      <td>rt neymarjr p alguem ai quer ser divulgado com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>saindo academia vim parar aniversario crianca ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5316</th>\n",
              "      <td>mutualloveoned tbm acho porem pobre pra compra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2686</th>\n",
              "      <td>rt barbarasousa vamos praia ver sol comer pizza</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28721</th>\n",
              "      <td>acabei ter inspiracao pra festa acontecer ne</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23960</th>\n",
              "      <td>rt diariope stanford jovens usam cigarro eletr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4990 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet  class\n",
              "6155   gente antiga starlanterns segue nessa conra ai...      0\n",
              "13614                 rafinha realmente sair fudeu vezkk      0\n",
              "7381   n vou fala nada pq gremio k joga contra ceara ...      0\n",
              "23925                                vamos flamengo crlh      0\n",
              "24251  rt neymarjr p alguem ai quer ser divulgado com...      0\n",
              "...                                                  ...    ...\n",
              "432    saindo academia vim parar aniversario crianca ...      1\n",
              "5316   mutualloveoned tbm acho porem pobre pra compra...      0\n",
              "2686     rt barbarasousa vamos praia ver sol comer pizza      1\n",
              "28721       acabei ter inspiracao pra festa acontecer ne      0\n",
              "23960  rt diariope stanford jovens usam cigarro eletr...      0\n",
              "\n",
              "[4990 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS7SNnWwsdyM"
      },
      "source": [
        "**Run training MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SjdXf7EseHv",
        "outputId": "0894afaa-7f17-42dd-a438-1a258ef6450d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "score = pipe.score(X_test, y_test)\n",
        "print('\\r{} [INFO] Score of MLP model with testing data is {:.1%}\\n'\n",
        "  .format(dt.datetime.now(), (1-train_size), score))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r2020-10-04 13:52:24.325200 [INFO] Score of MLP model with testing data is 20.0%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ud25BTlnnhV"
      },
      "source": [
        "**Cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1phUXpuOU1"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qacPkvbnn2u",
        "outputId": "d2dc11d9-1a0e-4f1e-f0ae-fbf10e08ef72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = cross_validate(pipe, X_train, y_train, cv=kfold)\n",
        "print(\"Average accuracy: %f (%f)\" %(results['test_score'].mean(), results['test_score'].std()))\n",
        "\n",
        "results = cross_val_predict(pipe, X_train, y_train, cv=kfold)\n",
        "metrics.accuracy_score(y_train, results)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: 0.967331 (0.001659)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.967331395931456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlf-tSrmouPt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRYLXOdvoung",
        "outputId": "b5ed09ee-4414-4f96-bbe8-533ce463568f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(metrics.classification_report(y_train, results, pipe.classes_))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     19375\n",
            "           1       0.40      0.23      0.29       583\n",
            "\n",
            "    accuracy                           0.97     19958\n",
            "   macro avg       0.69      0.61      0.64     19958\n",
            "weighted avg       0.96      0.97      0.96     19958\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyyxjlWnWtpm"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoadc_T0W5tg",
        "outputId": "7b6c620d-e4c8-4823-8a9f-2a8ac712202c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(pd.crosstab(y_train, results, rownames=['Real'], colnames=['Predicted'], margins=True))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted      0    1    All\n",
            "Real                        \n",
            "0          19174  201  19375\n",
            "1            451  132    583\n",
            "All        19625  333  19958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwKUlxnBeHm1"
      },
      "source": [
        "**Store MPL model in disk**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2AwkD3DeHHI",
        "outputId": "34fd6f1a-c57d-48d3-de8a-17d19deaad4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file_name = 'mlp_model'\n",
        "joblib.dump(pipe, file_name)\n",
        "print('\\rMPL model was saved sucessfully!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rMPL model was saved sucessfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SVAz9Mfgpic"
      },
      "source": [
        "**Load MLP model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn3G3aPygoO1"
      },
      "source": [
        "pipe = joblib.load(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07slT345Wy1w"
      },
      "source": [
        "**Predict tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxnj_CknoWgU",
        "outputId": "e112aef0-1fa3-42d3-d305-869e94d2360c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "tests = X_test\n",
        "predict_result = pipe.predict(X_test)\n",
        "\n",
        "pd.DataFrame(zip(tests, predict_result), columns=['tweet', 'class'])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gente antiga starlanterns segue nessa conra ai...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rafinha realmente sair fudeu vezkk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n vou fala nada pq gremio k joga contra ceara ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vamos flamengo crlh</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt neymarjr p alguem ai quer ser divulgado com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4985</th>\n",
              "      <td>saindo academia vim parar aniversario crianca ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4986</th>\n",
              "      <td>mutualloveoned tbm acho porem pobre pra compra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4987</th>\n",
              "      <td>rt barbarasousa vamos praia ver sol comer pizza</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4988</th>\n",
              "      <td>acabei ter inspiracao pra festa acontecer ne</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4989</th>\n",
              "      <td>rt diariope stanford jovens usam cigarro eletr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4990 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  class\n",
              "0     gente antiga starlanterns segue nessa conra ai...      0\n",
              "1                    rafinha realmente sair fudeu vezkk      0\n",
              "2     n vou fala nada pq gremio k joga contra ceara ...      0\n",
              "3                                   vamos flamengo crlh      0\n",
              "4     rt neymarjr p alguem ai quer ser divulgado com...      0\n",
              "...                                                 ...    ...\n",
              "4985  saindo academia vim parar aniversario crianca ...      1\n",
              "4986  mutualloveoned tbm acho porem pobre pra compra...      0\n",
              "4987    rt barbarasousa vamos praia ver sol comer pizza      1\n",
              "4988       acabei ter inspiracao pra festa acontecer ne      0\n",
              "4989  rt diariope stanford jovens usam cigarro eletr...      0\n",
              "\n",
              "[4990 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xaf95_65Upvl"
      },
      "source": [
        "**Prob for each class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOgsatvUqWb",
        "outputId": "2332d992-10a4-405f-d794-76b971cc190d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(pipe.classes_)\n",
        "pipe.predict_proba(X_test)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99963274e-01, 3.67256107e-05],\n",
              "       [9.99999776e-01, 2.23520385e-07],\n",
              "       [1.00000000e+00, 7.55476010e-12],\n",
              "       ...,\n",
              "       [5.43545902e-02, 9.45645410e-01],\n",
              "       [9.29623998e-01, 7.03760023e-02],\n",
              "       [9.99999448e-01, 5.52248436e-07]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKG3J_jC8LFI"
      },
      "source": [
        "### **3.2 - Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJl5Pqi8LFJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqRz0M58Rxv"
      },
      "source": [
        "### **3.3 - Sequential Minimal Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6I6HZT58Rxw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}